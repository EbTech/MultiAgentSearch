%File: formatting-instruction.tex
\documentclass[letterpaper]{article}
% AAAI format packages
\usepackage{aaai}
\usepackage{times}
\usepackage{helvet}
\usepackage{courier}
% Additional packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{comment}
\newtheorem{defn}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{cor}{Corollary}
\newtheorem{rul}{Expansion Rule}
% END Additional packages
\frenchspacing
\setlength{\pdfpagewidth}{8.5in}
\setlength{\pdfpageheight}{11in}
\pdfinfo{
/Title (Multi-Agent Path Planning with Constraints on Visitation Order)
%/Author (Aram Ebtekar, Mike Phillips, Sven Koenig, Maxim Likhachev)
/Keywords (weighted A* search, parallel algorithm, heuristic)
}
\setcounter{secnumdepth}{0}  
 \begin{document}
% The file aaai.sty is the style file for AAAI Press 
% proceedings, working notes, and technical reports.
%
\title{Multi-Agent Path Planning with Constraints on Visitation Order}
\author{Aram Ebtekar$^\dagger$ \and Mike Phillips$^\dagger$ \and Sven Koenig\thanks{University of Southern California, Los Angeles, CA 90089} \and Maxim Likhachev% <-this % stops a space
\thanks{Carnegie Mellon University, Pittsburgh, PA 15217}% <-this % stops a space
%
}
\author{AAAI 2016 Submission 2663}% anonymizer
\maketitle
\begin{abstract}
\begin{quote}
We consider path planning problems with multiple cooperating agents, each with its own start and goal position, the optimization target being the last time of arrival. The agents are coupled together by constraints on the order in which certain regions are visited. Such constraints can encode constructive interactions, where one agent enables the action of another, as well as destructive interactions, where one action precludes another thereafter. We describe how this class of constraints can describe a variety of practical domains in maintenance, surveillance, and assembly. Next we show that, unlike classical graph search, visitation order constrained planning is NP-hard to approximate. We present two planners, Fusion VOCA* and Greedy VOCA*. While the former guarantees completeness and a suboptimality factor equal to the number of agents, the latter is very efficient but may fail to yield a solution. Both planners augment the state space with a sequence of previously visited constraints, and this space is organized into a trie-like data structure. Finally, we compare the two planners experimentally, testing their scalability in terms of the number of constraints, agents and states.
\end{quote}
\end{abstract}

\section{Introduction}

The simplest motion planning domains, where the state is fully described by an agent's position in space, reduce to explicit shortest-paths problems on graphs upon discretization. On the other hand, high-level domain representations such as STRIPS compactly represent exponential-size graphs, which are NP-hard to search in general, and demand different techniques to incorporate the high-level information encoding the graph's structure. We explore a middle ground, often occupied by multi-task and/or cooperative multi-agent planning scenarios. The agents still move between locations on an explicit graph, but some aspect of their history is relevant toward determining which future moves are allowed. If multiple agents plan jointly, they may help or hinder one another.

A simple example is that of a robot A pressing a switch that opens a door which robot B must pass through. In this example, imagine either that robot B is incapable of pressing the switch due to physical limitations, or that the switch happens to lie conveniently on robot A's path so that collaboration results in faster plan execution. Thus, the $N$-agent problem cannot simply be solved by $N$ independent planners running in parallel. Nor would be want to search with a single planner over the joint state space of all $N$ agents, as that would result in exponential blowup even with a constant number of constraints.

We allow each agent to have a separate start and goal position, and specify constraints on the visitation order of certain sets of nodes. For instance, to describe a door that needs to be opened, we associate a set of nodes with the door-opening trigger and another set with the door itself, and insist that the trigger set is visited before the door. Other types of constraints can be described similarly: for instance, we may require that the second set is visited after the last time the first set is visited, as might be the case if the first set corresponds to using a coffee machine which needs to be cleaned up after its final use by the end of the day.

As the number of constraints grows, exponential blowup seems unavoidable in the worst case, as we will show that even obtaining a bounded suboptimal solution is NP-hard. Nonetheless, the two VOCA* algorithms presented in this paper can efficiently handle a large fraction of randomly generated test cases, provided either they are small or it is clear from the graph topology that the constraints can only interact in a few specific orders.

\section{Related Works}

Multi-agent planning is a growing field of research, as the emergent complexity of multi-agent systems raises the need for more advanced AI in both cooperative and competitive applications \cite{van2008multi}. Previous approaches for combining multiple individual plans into one consistent multi-agent plan include \cite{georgeff1988communication} and \cite{de2005multi}. Our approach is different in that, by restricting the set of allowable constraints, we are able to use simpler graph search methods in place of logical methods or complex representations such as STRIPS.

Different constraint formulations have been explored in the context of multi-agent planning. CBS, MA* and variants \cite{ferner2013odrm}\cite{sharon2015conflict}  adapt the dimensionality of the search to depend only on the number of agents which are actually in conflict. Our approach, in constrast, does all the low-level planning independently, but at the cost of a recombination step to merge the resulting plans. The DPC algorithm \cite{bhattacharya2010multi} also studied certain types of constraints between multiple agents. Here, multiple tasks need to be distributed among robots with time-parametrized constraints on their maximum distance. Our ordering constraints generalize the task distribution problem, but on the other hand we drop the distance constraints, lending our problem to more discrete methods.

We take the well-studied A* planning method \cite{hart1968formal}, and extend it to multi-agent systems which interact via a set of constraints. To our knowledge, the particular class of constraints we consider is new to the field of multi-agent path planning. It is essentially a very restricted subset of temporal logic \cite{gabbay1994temporal} in which every variable is monotonic: either constant, starts false and at some point shifts to becoming true thereafter, or starts true and shifts to becoming false. Some of the work most closely related to our own occured in the context of a generalized vehicle routing problem \cite{karaman2011linear}, for which techniques based on language automata and mixed-integer linear programming were developed. We focus on a more restricted class of problems, using classic graph search techniques and data structures.

\section{Problem Formulation}

A visitation order (VO)-constrained planning problem with $N$ agents and $K$ constraints is formulated in terms of $N$ weighted directed graphs $\{V_i,E_i,start_i,goal_i\}_{i=1}^N$ and $K$ \textbf{VO constraints} $\{\phi_i\}_{i=1}^K$. The vertex set $V_i$ contains the discrete positions accessible to agent $i$, including the special start and end positions $start_i,goal_i\in V_i$. Each edge $(u,v,w)\in E_i \subset V_i\times V_i\times [0,\infty)$ connects $u$ to $v$; it takes at least $w$ time units to traverse, but slower travel is permitted e.g. if one agent is pausing to wait for another. When such an edge exists, we may abuse notation and write $c(u,v) = w$. Otherwise, $c(u,v) = \infty$. We say the problem is \textbf{undirected} if $c(u,v) = c(v,u)$ for all $u,v$. Otherwise, it is \textbf{directed}.

A \textbf{plan} for agent $i$ is a sequence of ordered pairs $\pi_i = \langle (v_0,t_0),(v_1,t_1),\ldots,(v_m,t_m) \rangle$ such that $v_0 = start_i$, $v_m = goal_i$, $t_0 \ge 0$, and for all $j$: $v_j \in V_i$ and $t_{j} \ge t_{j-1} + c(v_{j-1},v_j)$. We say that $\pi_i$ \textbf{visits} $v_j$ at \textbf{time} $t_j$ and has \textbf{arrival time} $t_m$. An assignment of plans $\{\pi_i\}_{i=1}^N$ to all $N$ agents is called a \textbf{joint plan}, and is \textbf{valid} if it \textbf{satisfies} all $K$ of the VO constraints. The $\textbf{cost}$ of a joint plan is the maximum arrival time of its component plans. A planner's objective is to compute a valid joint plan of low cost; or in other words, to minimize the time at which all agents have reached their goals. If the cost is at most $\epsilon \ge 1$ times that of a minimum-cost valid joint plan, then we say the computed plan is $\epsilon$-optimal.

VO constraints impose certain order relations between the relative visit times of \textbf{regions} (sets of vertices) by agents. They come in four basic types:

\begin{itemize}
\item Door to Open: A ``door" corresponds to some region in one or more of the graphs. The door starts closed, but can be ``opened" by visiting an associated region corresponding to the door's ``trigger". Thus, the door region is traversible only after visiting the trigger region.
\item Door to Close: The door starts open, but is permanently ``closed" the first time an agent visits the trigger region. Thus, vertices in the door region can only be traversed before visiting the trigger region.
\item Use/Restore: If the ``use" region corresponds to using, say, a coffee machine, the ``restore" operation corresponds to cleaning it. The machine may be used and cleaned any number of times, but all uses must eventually be followed by a restore. Equivalently, no use can take place after the final restore.
\item Sequence: Here 2 regions must be visited, and the first visit of region 1 must precede the last visit of region 2. Imagine, for instance, that one agent must send a piece of information, e.g. an email, to another. The email may be sent multiple times, and the inbox may be checked multiple times, but the crucial requirement is that the receiving agent must finally see the email.
\end{itemize}

More formally, a VO constraint $\phi = \langle\phi^-,\phi^+,\tau\rangle$ is described by two vertex sets $\phi^-,\phi^+\subset \cup_i V_i$, along with a \textbf{constraint type} $\tau(\phi)$ describing the relationship $\phi$ imposes on the relative visit times of $\phi^-$ and $\phi^+$. To understand the constraint types, fix a joint plan $\{\pi_i\}_{i=1}^N$. For any vertex set $S \subset \cup_i V_i$, let $t_{min}(S)$ denote the very first time at which any $\pi_i$ visits any of the vertices in $S$. Likewise, let $t_{max}(S)$ denote the last time $S$ is visited. The four constraint types are defined by the following inequalities:

\begin{itemize}
\item O (open) constraint: $t_{\min}(\phi^-) \le t_{\min}(\phi^+)$
\item C (close) constraint: $t_{\max}(\phi^-) \le t_{\min}(\phi^+)$
\item R (restore) constraint: $t_{\max}(\phi^-) \le t_{\max}(\phi^+)$
\item S (sequence) constraint: $t_{\min}(\phi^-) \le t_{\max}(\phi^+)$
\end{itemize}

When the corresponding inequality is met, we say that $\{\pi_i\}_{i=1}^N$ satisfies $\phi$. Intuitively, an O constraint corresponds to a set of doors $\phi^+$, which start closed but can be permanently opened by triggering any one of the switches in $\phi^-$. In a C constraint, it is the $\phi^-$ vertices which should be thought of as doors, which are open until permanently barred shut by triggering a switch in $\phi^+$. In an R constraint, visiting $\phi^-$ is like using an appliance; after the final use, $\phi^+$ must be visited at least once in order to ``clean up". Finally, the S constraint simply dictates that some instance of $\phi^-$ take place before some instance of $\phi^+$.

Notice that if neither of $\phi^+,\phi^-$ are ever visited, then by the usual definition of $\min,\max$ of empty sets as $\infty, -\infty$ respectively, $\phi$ is satisfied iff it is not of type S. For $v\in \cup_i V_i$, we will use the notation $v^+ = \{\phi \mid v\in\phi^+\}$ to refer to the set of constraints $\phi$ such that $v\in\phi^+$, and likewise $v^- = \{\phi \mid v\in\phi^-\}$. To prevent technical ambiguities, we further require that for each $v$, either $v^+$ or $v^-$ is empty. In other words, $(\cup_{i=1}^K \phi_i^+) \cap (\cup_{i=1}^K \phi_i^-) = \emptyset$.

Later in this section, we will show how to convert R and S constraints into O and C constraints. The following theorem then states that without loss of generality, every joint plan can be expressed in terms of its component plans with all timestamps removed. This fact will prove helpful when we want to have agents plan independently, without knowing when and for how long they'll have to wait for one another.

\begin{thm}
\label{thm:greedy}
Suppose all constraints are of type O or C, and let $\{\pi_i\}_{i=1}^N$ be a joint plan with the visit times ommitted. Then there exists a greedy algorithm to check whether some assignment of visit times exists which would make the joint plan feasible and, if so, it will find one with minimum cost.
\end{thm} 

\begin{proof}
(Sketch): We propose the greedy algorithm which moves the agents in parallel along their respective plans at maximum speed, taking time equal to the edge costs when possible, but pausing when necessary to respect a constraint. If, while following a fixed path, we come across a door and it's open, clearly nothing is lost by passing through it at the earliest opportunity. Likewise if we see a trigger that opens a door, it's best to press it as soon as possible. What if we come across a trigger that would close doors? In this case, we should wait until all corresponding doors that will be encountered by the other agents have been passed. After that, we may proceed. Thus, we never get stuck as a result of a bad choice. If the algorithm does get stuck, failing to take every agent to its goal, then the joint plan cannot be made valid. On the other hand, if every agent reaches its goal, this algorithm obtains the smallest possible visit times.
\end{proof}

Of course, the conclusion also holds if all constraints are of type C or R, by simply reversing time and tracing paths from goal to start. Next, we show how to eliminate the additional constraint types with only a constant-factor blowup in the size of the problem description.

\begin{thm}
\label{thm:OC}
Any VO-constrained planning problem can be reduced to one involving only O and C constraints, such that every plan in one problem can be efficiently transformed into an equal-cost plan in the other.
\end{thm}

\begin{proof}
First, we sketch how to get rid of all R constraints. For clarity, we refer to the coffee machine use/clean terminology: $v$ \textbf{uses} $\phi$ if $v\in\phi^-$ and $\tau(\phi) = R$; $v$ \textbf{cleans} $\phi$ if $v\in\phi^+$ and $\tau(\phi) = R$. First, give each agent a new start node $start_i'$ which cleans all R constraints. Place a zero-cost directed edge from $start_i'$ to the original start $start_i$. Now, from every pair $v,\phi$ such that $v$ cleans $\phi$, draw bidirectional 0-cost edges from $v$ to a new vertex $v'$, and from $v'$ to a new vertex $v''$. Add a C constraint that closes access to $\phi^-$ upon access to $v'$, and an O constraint that opens access to some $goal_i$ upon access to $v''$. Accessing $v'$ and $v''$ is tantamount to deciding on the final clean for the coffee machine $\phi$, after which further use of $\phi$ is forbidden.

Finally to get rid of all S constraints, consider each pair $v,\phi$ such that $v\in\phi^+$ and $\tau(\phi) = S$. Connect $v$ bidirectionally to new vertices $v'$ followed by $v''$ as before. Now, add an O constraint which opens $v'$ whenever $\phi^-$ is visited, and another O constraint to open the goal when $v''$ is visited. It's easy to check that this encoding has the desired effect.
\end{proof}

Since R and S constraints can be represented in terms of O and C, we consider the latter pair as the only types without loss of generality. This allows us to use the greedy algorithm from Theorem \ref{thm:greedy}.

\section{Applications}

In distributed assembly, it is often necessary for one agent to complete its task before another agent can begin the next step. This is easily encoded by a type O constraint. In maintenance, a type R constraint can indicate that certain restoration tasks must follow equipment use in order to return everything to its original state.

More interesting encodings are possible in security and surveillance. If, say, $k$ agents must scan the same object, this can be encoded by giving each agent $k$ copies of the vertex where the scanning takes place, each of which opens one of $k$ O doors blocking the goal. Taking one of the copies activates a C trigger, blocking access to the agent' s remaining $k-1$, thus preventing the same agent from being counted twice. We can also require, for instance, that one agent from each of several assigned groups scan the item, by giving different agents control over different ``doors".

In a military or video game application similar to the main example in \cite{karaman2011linear}, one may be presented with a choice of routes to take, but also a series of enemy bases which block all routes within their respective ranges. Each base effectively blocks its neighboring routes via a C constraint. Thus, it is necessary to destroy or disable some of the bases before taking a route.


\section{Hardness Results}

In unconstrainted single-agent graph planning, the main difficulty stems from the graph being extremely large, often too large even to store in memory. If the graph were reasonably compact, say with only a million edges, then Dijkstra's algorithm finds the optimal path very efficiently. We might hope that something similar is true in the presence of VO constraints. However, we show here that unless P = NP, the complexity of VO-constrained planning is superpolynomial in $K$, the number of constraints. This is the case even if there is only one agent, unit edge costs, and we allow an arbitrarily large constant approximation factor. Thus, we may only hope to solve instances with few constraints in the worst case; for larger instances, we can only hope to find some structure or regularity in the realistic problem instances of a particular domain.

\begin{thm}
\label{NP1}
Determining the existence of a VO-constrained plan is NP-complete, even in the restricted case where there is only one agent and at most one of the following conditions holds:
\begin{itemize}
\item All constraints have type O.
\item The graph is undirected.
\end{itemize}
\end{thm}

\begin{proof}
First, we reduce 3-SAT to the directed version of the problem with only O constraints. Let's say there are $n$ variables $\{x_i\}_{i=1}^n$ and $m$ clauses $\{x_{a(i,1)} \vee x_{a(i,2)} \vee x_{a(i,3)} \}_{i=1}^m$. In addition to $start$ and $goal$, create the vertices $\{u_i\}_{i=0}^m$, $\{v_{i,1},v_{i,2},v_{i,3}\}_{i=1}^m$, as well as a vertex for each variable and its negation. Draw the edges
$(start,x_1),\;(start,\neg x_1),\;(x_i,x_{i+1}),\;(x_i,\neg x_{i+1}),\;
\\(\neg x_i,x_{i+1}),\;(\neg x_i,\neg x_{i+1}),\;(x_n,u_0),\;(\neg x_n,u_0),\;(u_{i-1},v_{i,j}),\;
\\(v_{i,j},u_i),\;(u_m,goal)$.
Finally, make O constraints so that $x_{a(i,j)}$ is needed to open $v_{i,j}$. Notice that $u_i$ is reachable from $u_{i-1}$ iff one of the variables from the $i$'th clause was triggered. Furthermore, it is impossible to trigger both a variable and its negation.

To handle the undirected case, follow a similar construction but use C constraints to block backtracking once a variable or its negation has been triggered. This effectively directs the graph as before.
\end{proof}

The above construction can be modified to have $|\phi^+| = |\phi^-| = 1$ and $|v^+ \cup v^-| \le 1$: simply replace the vertex corresponding to $x_i$ with a sequence of trigger nodes on a linear path, one for each clause containing $x_i$. Thus, even isolated constraints suffice to yield NP-completeness.

On the other hand, if only O constraints appear \emph{and} the graph is undirected, then greedily opening doors while exploring the graph in flood-fill fashion will always lead to a solution if one exists. Nonetheless, we may examine hardness of approximation. By considering the case where a set of randomly scattered triggers must all be pressed to open the goal, we can view VOC planning as a generalization of the Metric Traveling Salesman Problem. Since the latter admits polynomial-time constant-factor approximations \cite{christofides1976worst}, we might expect to find the same here. The following theorem trashes such hopes.

\begin{thm}
\label{thm:NP2}
Fix $\alpha < 1$. It is NP-hard to find an $\alpha ln(K)$-optimal VO-constrained plan, even when ALL of the following conditions hold:
\begin{itemize}
\item There is only $N=1$ agent.
\item All edges have zero or unit cost.
\item All constraints have type O.
\item The graph is undirected.
\item $|\phi^+| = |\phi^-| = 1$ for all constraints $\phi$.
\item $|v^+ \cup v^-| \le 1$ for all vertices $v$.
\end{itemize}
\end{thm}

\begin{proof}
This follows from the inapproximability of SET-COVER \cite{moshkovitz2012projection}. Let $\{S_i\}_{i=1}^n$ be a collection of sets. Draw a ``main path" of cost 0 from $start$ to $goal$, blocked at the goal end by doors corresponding to all the elements of $\cup_{i=1}^n S_i$. For each set $S_i$, draw an edge of cost 1, connecting the main path to a component corresponding to all the elements of $S_i$, all edges within the component having cost 0. The vertices of this component are triggers which open precisely the doors of the main path that correspond to elements of $S_i$. Thus, it costs 1 time time unit to open all the doors corresponding to the elements of each set $S_i$.
\end{proof}

\section{Algorithms}

Part of the difficulty in planning with these temporal constraints is that the set of actions available to one agent does not depend solely on its current position: it also depends on past positions visited by the agent and its collaborators. Perhaps the most obvious approach, then, is to plan directly over the joint state space, using a method such as A*. However, this yields absurdly many states and state transitions. Therefore, we opt for an approach where each agent runs an independent planner, and then the results are joined according to Theorem \ref{thm:greedy}.

\subsection{Fusion VOCA*}

Since individual plans may have to be interleaved in unpredictable ways, we save not only a bitmask but a sequence documenting the order in which constraints were triggered en route to the state under consideration. Indeed, each agent searches over an augmented graph whose vertices, called \textbf{states}, are elements of $V_i \times H$. Here, an element of $H$ is a (possibly empty) sequence of distinct regions of the form $\phi^+$ or $\phi^-$ for some constraint $\phi$. Thus, an agent's state is a combination of its present position and its history of encounters with constrained regions. In a forward A* search, the start state is $(start_i, \emptyset)$, and goals are any state of the form $(goal_i, hist)$ for $hist\in H$. Conversely, in backward A* search, the ''history" sequence contains future encounters, the search starts at $(goal_i, \emptyset)$, and ends at $(start_i, hist)$ for any $hist\in H$.

Each time a goal state $(goal_i, hist)$ is expanded, we can retrieve a plan for agent $i$ by following the backpointers in A*. At this time, we compare the new plan with every combination of known plans from the remaining $N-1$ agents, using the method of Theorem \ref{thm:greedy}.

\begin{thm}[Completeness with Bounded Suboptimality]
\label{thm:complete}
Fusion VOCA* (based on $w$-weighted A*) terminates, and returns a valid $Nw$-optimal joint plan, if one exists.
\end{thm}

\begin{proof}
Let $g^*$ be the optimal valid joint plan cost, and $g_i^*$ be the optimal distance in agent $i$'s graph to the goal state whose history sequence matches that of the joint optimal solution. To see that termination is guaranteed, note that since each state is expanded at most once, eventually, each agent expands its optimal goal state. As in $w$-weighted A*, the goal is expanded with cost at most $w g_i^*$, so the greedy algorithm will recover this joint plan with cost not exceeding $w \sum_i g_i^* \le w \sum_i g^* = Nw g^*$. Therefore, the termination condition holds.

Now, assuming the termination condition, we want to bound the optimality factor on our plan. Based on the above, we know that at least one of the agents has not expanded its optimal goal state $s$. Let $s'$ be the earliest state in the open list on the optimal path from $start$ to $s$. Then $f(s') = g(s') + wh(s') \le w(g^*(s') + h(s')) \le w g_i^*$. But $jointCost \le N \min_{i=1}^N f_{min,i}$, so $jointCost \le Nw g_i^* \le Nw g^*$.
\end{proof}

\subsection{Greedy VOCA*}

This algorithm simply plans for each agent $1,\ldots,N$ in turn, greedily making choices and committing to them. Since these choices might not have a continuation into a valid joint plan, this approach is necessarily incomplete. On the other hand, it is fast because it only searches for one path to the goal per agent. When planning for agent $i$, the algorithm tries to maintain its commitments to the plans it found for agents $1,
\ldots,i-1$, all while optimistically assuming that agents $i+1,\ldots,N$ will pose no obstacles and conveniently open any doors reachable from their respective graphs. While Greedy VOCA* makes no global guarantees, locally it will find a $w$-optimal path consistent for agent $i$ consistent with all its prior commitments.

\subsection{Data Structures}
A \textbf{state} is the search space of agent $i$ is an ordered pair $(v, hist)$ of vertex $v\in V_i$ and history sequence $hist\in H$. States are organized into a trie and accessed by following edges corresponding to the sequence of constraints named in $hist$. Having arrived at the right trie node for $hist$, data corresponding to the state $(v, hist)$ is retrieved by looking it up in a map stored in this node. This data structure allows for efficient traversal of the state graph without having to repeatedly compute a hash function of the entire $hist$ sequence array. Furthermore, the trie node contains stores information common to all the states with the same constraint-oriented history, such as bitmasks representing the set of activated triggers.

\subsection{Heuristic}
As our A* heuristic, we simply precomputed distances to the goal in the relaxed problem, where each agent plans on its own and passes freely through all constraints.

\section{Experiments}

\subsection{Setup}
We tested both versions of VOCA* with weight $w = 1$ on random 2D mazes with O and C door-type constraints. A ``maze" consists of $N$ $r$x$r$ square grids, one for each agent. We used a standard DFS maze generator to fill the squares with thin passages. We then chose a sequence of cells across all the grids, such that they can be visited in linear order, possibly with pauses and backtracking. We also built a random consistent sequence of constraint interactions, and mapped them onto the sequence of grid cells. By construction, a solution is guaranteed to exist. To toss in additional confusion, each cell not belonging to the main sequence, whether it was originally an empty space or a wall, has a 0.25\% chance of being converted into each possible type of constraint cell (e.g. a trigger for a particular door).

Three parameters were varied: the number of constraints, the number of agents, and the maze dimensions. We varied each parameter individually while keeping the other two fixed, resulting in Tables 1-3. The numbers on the left side of each table cell correspond to Fusion VOCA*, while the numbers on the right correspond to Greedy VOCA*. For each setting of the parameters, 10 mazes were randomly generated. Median times (in seconds) and expansion counts were computed by taking means of the 5th and 6th ranking result. Each algorithm was given a maximum of 2 minutes to solve each maze on a 3.4 GHz Intel Core i7-2600 CPU.

\subsection{Results}

The costs of solutions found by Fusion and Greedy VOCA* were very similar. The key empirical difference is that the greedy algorithm is much faster, but often terminates empty-handed, especially as the number of agents gets large. On the other hand, the runtime of Fusion VOCA* varies greatly: while the median runtime is fairly low (at least while the number of agents and constraints is under control), it occasionally goes way over the 2-minute time limit. Nonetheless, notice that Fusion does not perform substantially more expansions than Greedy. The true bottleneck in the slow cases is an accumulation of alternative paths to the goal, leading to exponentially many $N$-tuples that need to be tested.

\begin{table}
\centering
\begin{tabular} {|c|c|c|c|} \hline
\# Constraints & Median Time & Median \#Exps & \#Solved \\ \hline
3 & .0017/.0007 & 662/479 & 10/7 \\ \hline
7 & .0029/.0009 & 697/799 & 10/7 \\ \hline
11 & .0115/.0008 & 980/662 & 8/7 \\ \hline
15 & 89.68/.0039 & 3465/3927 & 6/4 \\ \hline
\end{tabular}
\caption{7 agents on 17x17 mazes}
\label{tab:doors}
\end{table}

\begin{table}
\centering
\begin{tabular} {|c|c|c|c|} \hline
\# Agents & Median Time & Median \#Exps & \#Solved \\ \hline
3 & .0009/.0003 & 270/262 & 10/9 \\ \hline
7 & .0029/.0009 & 697/799 & 10/7 \\ \hline
11 & .0083/.0010 & 1111/1321 & 10/1 \\ \hline
15 & .0127/.0015 & 1313/1449 & 7/1 \\ \hline
\end{tabular}
\caption{7 constraints on 17x17 mazes}
\label{tab:agents}
\end{table}

\begin{table}
\centering
\begin{tabular} {|c|c|c|c|} \hline
Maze Size & Median Time & Median \#Exps & \#Solved \\ \hline
9x9 & .0008/.0003 & 270/224 & 10/4 \\ \hline
17x17 & .0029/.0009 & 697/799 & 10/7 \\ \hline
25x25 & .0103/.0029 & 1103/3022 & 10/5 \\ \hline
35x35 & .4645/.0116 & 3623/22021 & 7/4 \\ \hline
\end{tabular}
\caption{7 constraints and 7 agents}
\label{tab:rows}
\end{table}

\section{Future Work}

We presented two algorithms for planning with multiple-agents tied by visitation order constraints. Fusion VOCA* is a rigorous approach that guaranteed completeness with bounded suboptimality. Greedy VOCA*, on the other hand, trades completeness for speed, and succeeds in a good fraction of the cases we generated. Thus, it seems advisable to try the greedy approach first, and if it fails, fall back to the fusion approach.

When there are many agents, we found that the actual planning part of Fusion VOCA* is considerably faster than the fusion step which it invokes to test every new $N$-tuple of known paths. Although the testing for a single tuple is quick and greedy, the number of such tuples can be exponential in the number of agents $N$. It would be interesting to see if the latter bottleneck could be removed while preserving completeness and bounded suboptimality.  It would also be worthwhile to develop better heuristics that somehow capture the interdependence between the agents in a constrained planning scenario.

\begin{algorithm}
\caption{$search()$}
\label{alg:update}
\begin{algorithmic}
\STATE $jointCost = \infty$
\WHILE {$N \min_{i=1}^N f_{min,i} < jointCost$}
\STATE choose $i\in\{1,\ldots,N\}$ such that $OPEN_{i}$ is not empty
\STATE $(pos, hist_i)$ := remove from the front of $OPEN_{i}$
\IF {$pos = start_{i}$}
\FORALL {tuples $(hist_1,\ldots,hist_{i-1},hist_{i+1},\ldots,hist_N)$}
\STATE $jointCost := \min(jointCost,jointPriority($\\\qquad$(start_i,hist_i),\ldots,(start_N,hist_N)))$
\ENDFOR
\ENDIF
\STATE $expand(pos, hist)$
\ENDWHILE
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{$expand(pos, hist)$}
\label{alg:update}
\begin{algorithmic}
\STATE mark $(pos, hist)$ as CLOSED
\FORALL {$(pos', hist') \in successors(pos, hist)$}
\IF {$g(pos', hist') > g(pos, hist) + c(pos, pos')$}
\STATE $g(pos', hist') := g(pos, hist) + c(pos, pos')$
\STATE $bp(pos', hist') := (pos, hist)$
\IF {$(pos', hist')$ is not CLOSED}
\STATE insert $(pos', hist')$ in $agent.OPEN$
\ENDIF
\ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}

\begin{comment}

\begin{algorithm}
\caption{$MultiAgent A^*HighLevel()$}
\label{alg:update}
\begin{algorithmic}
\STATE $\forall i:\; s_i := start_i$
\WHILE {$g(goal_1, \ldots, goal_N) > f(s_1,\ldots,s_N)$}
\STATE $\forall i:\; expand(s_i)$
\STATE $(s_1,\ldots,s_N) = \arg\min_{s_1,\ldots,s_N} f(s_1,\ldots,s_N)$
\ENDWHILE
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{$f(s)$}
\label{alg:update}
\begin{algorithmic}
\STATE $f := \infty$
\FORALL {tuples $s_{1\ldots N}\in OPEN$ that include $s$}
\STATE $f := \min(f, jointPriority(s_{1\ldots N}))$
\ENDFOR
\RETURN $f$
\end{algorithmic}
\end{algorithm}

\end{comment}

\begin{algorithm}
\caption{$successors(u, seq_u)$}
\label{alg:update}
\begin{algorithmic}
\STATE succlist := $\emptyset$
\FORALL{$v$ such that $c(u,v) < \infty$}
\STATE $seq_v := seq_u$
\FORALL {min constraints $\phi^\pm \notin seq_u$ with $v\in\phi^\pm$}
\STATE append $\phi^\pm$ to $seq_v$
\ENDFOR
\FORALL {max constraints $\phi^\pm$ with $v\in\phi^\pm$}
\STATE remove $\phi^\pm$ from $seq_v$
\STATE append $\phi^\pm$ to $seq_v$
\ENDFOR
\STATE push $(v,seq_v)$ onto succlist
\ENDFOR
\RETURN succlist
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{$greedyCost(\pi_1,\ldots,\pi_n)$}
\label{alg:update}
\begin{algorithmic}
\STATE $\forall\phi:\; trigger(\phi) := \tau(\phi) = O$ \OR $\phi^-$ is absent in $\pi_{1\ldots N}$
\STATE $\forall \i\in 1\ldots N:\; u_i := v_i := start_i$
\STATE $events := \{0: \{1\ldots N\}\}$
\WHILE {$events$ is not empty}
\STATE $(time, ids) := extractMin(events)$
\FORALL {$i\in ids$}
\STATE $u_i := v_i$
\FORALL {$\phi \in v^-$}
\IF {$\tau(\phi) = O$ \OR $\phi^-$ appears in no suffix of $\pi_{1\ldots N}$ after $u_{1\ldots N}$}
\STATE $trigger(\phi) := true$
\ENDIF
\ENDFOR
\ENDFOR
\FORALL {$i\in 1\ldots N$ with $u_i = v_i \neq goal_i$}
\STATE $v_i :=$ successor of $u_i$ on $\pi_i$
\FORALL {$\phi \in v^+$}
\IF {$\neg trigger(\phi)$}
\STATE $v_i := u_i$ and continue with the next $i$
\ENDIF
\ENDFOR
\STATE $events(time+c(u_i,v_i)).insert(i)$
\ENDFOR
\ENDWHILE
\IF {$u_{1\ldots N} = goal_{1\ldots N}$}
\RETURN $time$
\ELSE
\RETURN $\infty$
\ENDIF
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{$jointPriority((pos_1,hist_1),\ldots,(pos_N,hist_N))$}
\label{alg:update}
\begin{algorithmic}
\STATE $\forall i$, build $\pi_i$ by following $bp()$ from $(pos_i, hist_i)$
\FORALL {$i\in 1\ldots N$ such that $pos_i \ne start_i$}
\STATE extend $\pi_i$ with a zero cost edge to a node that opens all doors the agent can open, followed by $start_i$ at cost $\epsilon h(s_i)$
\ENDFOR
\RETURN $greedyCost(\pi_1,\ldots,\pi_n)$
\end{algorithmic}
\end{algorithm}

\bibliographystyle{aaai}
\bibliography{ma}

\end{document}
